{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2277e4e-c76c-4216-ad38-3496222429a9",
   "metadata": {},
   "source": [
    "# Usage Guide: Automating PyTorch Loss Functions with Rubick on CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c34ec0-adfc-4d78-ac3d-4f66d11f468c",
   "metadata": {},
   "source": [
    "### Importing Libraries\n",
    "\n",
    "Here we import `Rubick` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1856fb82-0c8f-437f-a1ef-77c64eb61c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from rubick_v6 import Rubick"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0259b8c-7de3-43c6-9e11-66adf1ef8488",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ce993f5-ed06-466a-b147-6989aed77a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 170M/170M [00:01<00:00, 98.3MB/s]\n",
      "/home/gss119/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a041b728-5a4c-42c1-9b08-77f9602cee54",
   "metadata": {},
   "source": [
    "### Defining simple model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15338791-aed6-4206-b916-c26ae2228f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 8 * 8, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = SimpleCNN().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658036b0-0940-4703-85e7-fb9c4ea9ce9d",
   "metadata": {},
   "source": [
    "### Generating loss function using Rubick"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46234792-84e1-4bfe-9b16-8bb746b27b15",
   "metadata": {},
   "source": [
    "We have defined the neural network architecture and prepared the data in the above code cells. Now we have to define the loss function based on which the model will be evaluated on in the training process.\n",
    "\n",
    "We choose the `CodeLlama-7b-Instruct-hf` model as it performs well in coding and also while following instructions. \n",
    "\n",
    "As you can see in the output below, the model fails to generate a valid loss function in the first loop - the loss function fails the unit test on all three attempts. \n",
    "\n",
    "In the second loop, the model generates a valid loss function in the first attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e807d92-f3b3-4c0a-a8af-80c064ccfebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7314d5459fe64936b10d6c112481c8e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting loss function generation process\n",
      "Here is initial code generated for loop:  0\n",
      "\n",
      "Loss function code:\n",
      "  import torch\n",
      "import torch.nn as nn\n",
      "import torch.nn.functional as F\n",
      "\n",
      "class AutoLoss(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(AutoLoss, self).__init__()\n",
      "\n",
      "    def forward(self, x, y):\n",
      "        return F.cross_entropy(x, y)\n",
      "\n",
      "Test function code:\n",
      " from temp_code import AutoLoss\n",
      "\n",
      "import unittest\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "import torch.nn.functional as F\n",
      "\n",
      "class AutoLossTest(unittest.TestCase):\n",
      "    def test_loss_function(self):\n",
      "        loss_fn = AutoLoss()\n",
      "        x = torch.randn(5, 3)\n",
      "        y = torch.randint(0, 3, (5,))\n",
      "        loss = loss_fn(x, y)\n",
      "        self.assertTrue(loss.requires_grad)\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    unittest.main()\n",
      "\n",
      "[Attempt 1/3] Status: False\n",
      "Error Output:\n",
      "test_loss_function (temp_test.AutoLossTest) ... FAIL\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_loss_function (temp_test.AutoLossTest)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/cache/home/gss119/Documents/Loss Function Generation/git_repo/Automating-Loss-Function-Generation-Using-LLMs/temp_gen/temp_test.py\", line 14, in test_loss_function\n",
      "    self.assertTrue(loss.requires_grad)\n",
      "AssertionError: False is not true\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.001s\n",
      "\n",
      "FAILED (failures=1)\n",
      "\n",
      "\n",
      "\n",
      " Rubick found an error and says the error is in: loss - <class 'str'>\n",
      "[Fixing Loss Function]\n",
      "\n",
      "[Attempt 2/3] Status: False\n",
      "Error Output:\n",
      "test_loss_function (temp_test.AutoLossTest) ... FAIL\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_loss_function (temp_test.AutoLossTest)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/cache/home/gss119/Documents/Loss Function Generation/git_repo/Automating-Loss-Function-Generation-Using-LLMs/temp_gen/temp_test.py\", line 14, in test_loss_function\n",
      "    self.assertTrue(loss.requires_grad)\n",
      "AssertionError: False is not true\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.000s\n",
      "\n",
      "FAILED (failures=1)\n",
      "\n",
      "\n",
      "\n",
      " Rubick found an error and says the error is in: loss - <class 'str'>\n",
      "[Fixing Loss Function]\n",
      "\n",
      "[Attempt 3/3] Status: False\n",
      "Error Output:\n",
      "test_loss_function (temp_test.AutoLossTest) ... FAIL\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_loss_function (temp_test.AutoLossTest)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/cache/home/gss119/Documents/Loss Function Generation/git_repo/Automating-Loss-Function-Generation-Using-LLMs/temp_gen/temp_test.py\", line 14, in test_loss_function\n",
      "    self.assertTrue(loss.requires_grad)\n",
      "AssertionError: False is not true\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.000s\n",
      "\n",
      "FAILED (failures=1)\n",
      "\n",
      "\n",
      "\n",
      " Rubick found an error and says the error is in: loss - <class 'str'>\n",
      "[Fixing Loss Function]\n",
      "Here is initial code generated for loop:  1\n",
      "\n",
      "Loss function code:\n",
      "  import torch\n",
      "import torch.nn as nn\n",
      "import torch.nn.functional as F\n",
      "\n",
      "class AutoLoss(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(AutoLoss, self).__init__()\n",
      "\n",
      "    def forward(self, x, y):\n",
      "        return F.cross_entropy(x, y, reduction='mean')\n",
      "\n",
      "    def __repr__(self):\n",
      "        return f\"{self.__class__.__name__}()\"\n",
      "\n",
      "    def __call__(self, x, y):\n",
      "        return self.forward(x, y)\n",
      "\n",
      "Test function code:\n",
      " from temp_code import AutoLoss\n",
      "\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "import torch.nn.functional as F\n",
      "\n",
      "class AutoLoss(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(AutoLoss, self).__init__()\n",
      "\n",
      "    def forward(self, x, y):\n",
      "        return F.cross_entropy(x, y, reduction='mean')\n",
      "\n",
      "    def __repr__(self):\n",
      "        return f\"{self.__class__.__name__}()\"\n",
      "\n",
      "    def __call__(self, x, y):\n",
      "        return self.forward(x, y)\n",
      "\n",
      "# Testing the loss function\n",
      "\n",
      "# Initialize the loss function\n",
      "loss_fn = AutoLoss()\n",
      "\n",
      "# Test the forward pass\n",
      "x = torch.randn(5, 3)\n",
      "y = torch.randint(0, 3, (5,))\n",
      "\n",
      "# Calculate the loss\n",
      "loss = loss_fn(x, y)\n",
      "\n",
      "# Check if the loss is a scalar\n",
      "assert loss.shape == ()\n",
      "\n",
      "# Check if the loss is positive\n",
      "assert loss.item() > 0\n",
      "\n",
      "# Check if the loss is the same as the expected value\n",
      "expected_loss = F.cross_entropy(x, y, reduction='mean')\n",
      "assert torch.isclose(loss, expected_loss)\n",
      "\n",
      "[Attempt 1/3] Status: True\n",
      "Error Output:\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 0 tests in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "\n",
      "Tests passed successfully!\n",
      "\n",
      "Loss function generated successfully. Executing generated function.\n",
      "Loss function executed and is now ready to use!\n"
     ]
    }
   ],
   "source": [
    "model_id = \"codellama/CodeLlama-7b-Instruct-hf\"\n",
    "token = \"NONE\"\n",
    "prompt = \"The task is to create a loss function for a 10-class image classification task on the CIFAR-10 dataset\"\n",
    "\n",
    "generator = Rubick(model_id, token, prompt)\n",
    "generator.process_start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b66d567-a28d-4d75-aa4f-86a736562877",
   "metadata": {},
   "source": [
    "### Setting AutoLoss as the loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f550faa-7393-48a0-a0cc-a307de3269e2",
   "metadata": {},
   "source": [
    "Here we assign the generated loss function `AutoLoss` to the variable `criterion` which will then be used for the rest of the training phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9e44021-4056-46e0-9644-d8480bed49f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = generator.AutoLoss().to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee84127-dc0b-48f4-affa-b60af68781c3",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad754e14-667a-47ff-b0cb-3fe2ed8e2fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gss119/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 2 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 100] loss: 1.798\n",
      "[1, 200] loss: 1.483\n",
      "[1, 300] loss: 1.329\n",
      "[1, 400] loss: 1.243\n",
      "[1, 500] loss: 1.205\n",
      "[1, 600] loss: 1.116\n",
      "[1, 700] loss: 1.078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 100] loss: 0.973\n",
      "[2, 200] loss: 0.935\n",
      "[2, 300] loss: 0.929\n",
      "[2, 400] loss: 0.910\n",
      "[2, 500] loss: 0.912\n",
      "[2, 600] loss: 0.869\n",
      "[2, 700] loss: 0.863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 100] loss: 0.759\n",
      "[3, 200] loss: 0.760\n",
      "[3, 300] loss: 0.759\n",
      "[3, 400] loss: 0.737\n",
      "[3, 500] loss: 0.744\n",
      "[3, 600] loss: 0.759\n",
      "[3, 700] loss: 0.738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 100] loss: 0.621\n",
      "[4, 200] loss: 0.587\n",
      "[4, 300] loss: 0.630\n",
      "[4, 400] loss: 0.613\n",
      "[4, 500] loss: 0.619\n",
      "[4, 600] loss: 0.634\n",
      "[4, 700] loss: 0.607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 100] loss: 0.466\n",
      "[5, 200] loss: 0.477\n",
      "[5, 300] loss: 0.489\n",
      "[5, 400] loss: 0.492\n",
      "[5, 500] loss: 0.494\n",
      "[5, 600] loss: 0.478\n",
      "[5, 700] loss: 0.514\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):  # 5 epochs\n",
    "    running_loss = 0.0\n",
    "    model.train()\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(trainloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:\n",
    "            print(f\"[{epoch + 1}, {i + 1}] loss: {running_loss / 100:.3f}\")\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fc6170-2707-4bbd-8dd5-741d3949dde0",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1614d224-9e9f-4a0a-8fb8-e9a6a61937b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on CIFAR-10 test images: 72.22%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on CIFAR-10 test images: {100 * correct / total:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
