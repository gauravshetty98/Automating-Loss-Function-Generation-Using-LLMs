{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5954b41-9102-4934-9933-e2733dc45372",
   "metadata": {},
   "source": [
    "# Usage guide: Loss function generation and error correction using Rubick"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4525b21a-b6c6-4f82-bfac-3d50057330f3",
   "metadata": {},
   "source": [
    "This notebook demonstrates the usage of the `Rubick` class to automatically generate a PyTorch-compatible loss function for a simple classification task on the MNIST dataset.\n",
    "\n",
    "Rather than showcasing a full end-to-end training pipeline, the focus here is on evaluating Rubick's ability to:\n",
    "\n",
    "- Generate an initial loss function based on a user-defined prompt (\"The task is to classify images present in MNIST dataset\")\n",
    "- Identify and respond to a runtime error during unit testing\n",
    "- Correct the loss function in the second loop using its internal logic\n",
    "- Produce a final, valid loss function that passes the unit test\n",
    "\n",
    "This example highlights Rubick's core capability: automated, iterative debugging and correction of AI-generated code â€” particularly useful for streamlining model prototyping and experiment setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43ee8223-62ed-4f8d-8990-ca6dc6d9b010",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from rubick import Rubick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10dd1bf5-8577-4c31-bf21-a11847d3aa2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3bec54c51144719a9674a3c79d4e367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting loss function generation process\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "import torch.nn.functional as F\n",
      "\n",
      "class AutoLoss(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(AutoLoss, self).__init__()\n",
      "\n",
      "    def forward(self, input, target):\n",
      "        return F.cross_entropy(input, target)\n",
      "import unittest\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "import torch.nn.functional as F\n",
      "\n",
      "class TestAutoLoss(unittest.TestCase):\n",
      "    def setUp(self):\n",
      "        self.model = AutoLoss()\n",
      "\n",
      "    def test_forward(self):\n",
      "        input = torch.randn(3, 5)\n",
      "        target = torch.randint(0, 5, (3,))\n",
      "        output = self.model(input, target)\n",
      "        self.assertTrue(isinstance(output, torch.Tensor))\n",
      "        self.assertTrue(output.shape == (3,))\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    unittest.main()\n",
      "Here is initial code generated for loop:  0\n",
      "Loss function code: import torch\n",
      "import torch.nn as nn\n",
      "import torch.nn.functional as F\n",
      "\n",
      "class AutoLoss(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(AutoLoss, self).__init__()\n",
      "\n",
      "    def forward(self, input, target):\n",
      "        return F.cross_entropy(input, target)\n",
      "test function code: from temp_code import AutoLoss\n",
      "\n",
      "import unittest\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "import torch.nn.functional as F\n",
      "\n",
      "class TestAutoLoss(unittest.TestCase):\n",
      "    def setUp(self):\n",
      "        self.model = AutoLoss()\n",
      "\n",
      "    def test_forward(self):\n",
      "        input = torch.randn(3, 5)\n",
      "        target = torch.randint(0, 5, (3,))\n",
      "        output = self.model(input, target)\n",
      "        self.assertTrue(isinstance(output, torch.Tensor))\n",
      "        self.assertTrue(output.shape == (3,))\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    unittest.main()\n",
      "\n",
      "[Attempt 1/3] Status: False\n",
      "Error Output:\n",
      "test_forward (temp_test.TestAutoLoss) ... FAIL\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_forward (temp_test.TestAutoLoss)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/cache/home/gss119/Documents/Loss Function Generation/git_repo/Automating-Loss-Function-Generation-Using-LLMs/temp_gen/temp_test.py\", line 17, in test_forward\n",
      "    self.assertTrue(output.shape == (3,))\n",
      "AssertionError: False is not true\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.001s\n",
      "\n",
      "FAILED (failures=1)\n",
      "\n",
      "\n",
      "Rubick says the error is in: loss - <class 'str'>\n",
      "Rubick says the error is in:  loss\n",
      "[Fixing Loss Function]\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "import torch.nn.functional as F\n",
      "\n",
      "class AutoLoss(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(AutoLoss, self).__init__()\n",
      "\n",
      "    def forward(self, input, target):\n",
      "        return F.cross_entropy(input, target, reduction='none')\n",
      "\n",
      "[Attempt 2/3] Status: True\n",
      "Error Output:\n",
      "test_forward (temp_test.TestAutoLoss) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "\n",
      "Tests passed successfully!\n",
      "Loss function generated successfully. Executing generated function.\n",
      "\n",
      "=== Extracted Code Being Executed ===\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "import torch.nn.functional as F\n",
      "\n",
      "class AutoLoss(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(AutoLoss, self).__init__()\n",
      "\n",
      "    def forward(self, input, target):\n",
      "        return F.cross_entropy(input, target, reduction='none')\n",
      "=====================================\n",
      "\n",
      "Loss function executed and is now ready to use!\n"
     ]
    }
   ],
   "source": [
    "model_id = \"codellama/CodeLlama-7b-Instruct-hf\"\n",
    "token = \"None\"\n",
    "prompt = \"The task is to classify images present in MNIST dataset\"\n",
    "\n",
    "generator = Rubick(model_id, token, prompt)\n",
    "generator.process_start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
