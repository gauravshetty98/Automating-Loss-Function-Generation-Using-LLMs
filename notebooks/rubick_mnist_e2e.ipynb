{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "864e0e86-a8aa-4a28-aeba-51dd93632e9b",
   "metadata": {},
   "source": [
    "# Usage Guide: Automating PyTorch Loss Functions with Rubick on MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3369f7bd-e119-4661-b1b0-8348f01b48da",
   "metadata": {},
   "source": [
    "### Importing necessary libraries\n",
    "\n",
    "Here we import `Rubick` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "648a4de5-f59d-4a9a-a812-2acd066b0e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from rubick_v6 import Rubick"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd61853-c0c5-4980-94aa-3a8d61dc185d",
   "metadata": {},
   "source": [
    "### Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a813962-b9dc-414b-8f78-199f7f909a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e4df36-96f2-415a-a392-cb087e7302c2",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c578560f-302e-4db8-afcf-2cd0a3942e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)  # flatten the image\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleNN().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eee7b96-b3d2-4470-ab9b-90c5f1a589b9",
   "metadata": {},
   "source": [
    "### Generating loss function\n",
    "\n",
    "We have defined the neural network architecture and prepared the data in the above code cells. Now we have to define the loss function based on which the model will be evaluated on in the training process.\n",
    "\n",
    "We choose the `CodeLlama-7b-Instruct-hf` model as it performs well in coding and also while following instructions. \n",
    "\n",
    "As you can see in the output below, the model fails to generate a valid loss function in the first loop - the loss function fails the unit test on all three attempts. \n",
    "\n",
    "In the second loop, the model generates a valid loss function in the first attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a8f9b81-9411-4348-b506-47e7ecbba9e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5887d5376cb34058a7100e111d3afea8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting loss function generation process\n",
      "Here is initial code generated for loop:  0\n",
      "\n",
      "Loss function code:\n",
      "  import torch\n",
      "import torch.nn as nn\n",
      "import torch.nn.functional as F\n",
      "\n",
      "class AutoLoss(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(AutoLoss, self).__init__()\n",
      "\n",
      "    def forward(self, y_pred, y_true):\n",
      "        # Compute the loss\n",
      "        loss = F.cross_entropy(y_pred, y_true)\n",
      "\n",
      "        return loss\n",
      "\n",
      "Test function code:\n",
      " from temp_code import AutoLoss\n",
      "\n",
      "import unittest\n",
      "\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "import torch.nn.functional as F\n",
      "\n",
      "class AutoLossTest(unittest.TestCase):\n",
      "    def test_auto_loss_forward(self):\n",
      "        # Define the input and output tensors\n",
      "        y_pred = torch.randn(10, 10)\n",
      "        y_true = torch.randint(0, 10, (10,))\n",
      "\n",
      "        # Instantiate the loss function\n",
      "        loss_fn = AutoLoss()\n",
      "\n",
      "        # Forward pass\n",
      "        loss = loss_fn(y_pred, y_true)\n",
      "\n",
      "        # Check if the output is a tensor\n",
      "        self.assertTrue(torch.is_tensor(loss))\n",
      "\n",
      "        # Check if the output has the expected shape\n",
      "        self.assertEqual(loss.shape, (1,))\n",
      "\n",
      "        # Check if the output is a scalar\n",
      "        self.assertTrue(loss.numel() == 1)\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    unittest.main()\n",
      "\n",
      "[Attempt 1/3] Status: False\n",
      "Error Output:\n",
      "test_auto_loss_forward (temp_test.AutoLossTest) ... FAIL\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_auto_loss_forward (temp_test.AutoLossTest)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/cache/home/gss119/Documents/Loss Function Generation/git_repo/Automating-Loss-Function-Generation-Using-LLMs/temp_gen/temp_test.py\", line 25, in test_auto_loss_forward\n",
      "    self.assertEqual(loss.shape, (1,))\n",
      "AssertionError: torch.Size([]) != (1,)\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.001s\n",
      "\n",
      "FAILED (failures=1)\n",
      "\n",
      "\n",
      "\n",
      " Rubick found an error and says the error is in: loss - <class 'str'>\n",
      "[Fixing Loss Function]\n",
      "\n",
      "[Attempt 2/3] Status: False\n",
      "Error Output:\n",
      "test_auto_loss_forward (temp_test.AutoLossTest) ... FAIL\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_auto_loss_forward (temp_test.AutoLossTest)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/cache/home/gss119/Documents/Loss Function Generation/git_repo/Automating-Loss-Function-Generation-Using-LLMs/temp_gen/temp_test.py\", line 25, in test_auto_loss_forward\n",
      "    self.assertEqual(loss.shape, (1,))\n",
      "AssertionError: torch.Size([10]) != (1,)\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.000s\n",
      "\n",
      "FAILED (failures=1)\n",
      "\n",
      "\n",
      "\n",
      " Rubick found an error and says the error is in: loss - <class 'str'>\n",
      "[Fixing Loss Function]\n",
      "\n",
      "[Attempt 3/3] Status: False\n",
      "Error Output:\n",
      "test_auto_loss_forward (temp_test.AutoLossTest) ... FAIL\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_auto_loss_forward (temp_test.AutoLossTest)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/cache/home/gss119/Documents/Loss Function Generation/git_repo/Automating-Loss-Function-Generation-Using-LLMs/temp_gen/temp_test.py\", line 25, in test_auto_loss_forward\n",
      "    self.assertEqual(loss.shape, (1,))\n",
      "AssertionError: torch.Size([10]) != (1,)\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.011s\n",
      "\n",
      "FAILED (failures=1)\n",
      "\n",
      "\n",
      "\n",
      " Rubick found an error and says the error is in: loss - <class 'str'>\n",
      "[Fixing Loss Function]\n",
      "Here is initial code generated for loop:  1\n",
      "\n",
      "Loss function code:\n",
      "  import torch\n",
      "import torch.nn as nn\n",
      "import torch.nn.functional as F\n",
      "\n",
      "class AutoLoss(nn.Module):\n",
      "    def __init__(self):\n",
      "        super(AutoLoss, self).__init__()\n",
      "\n",
      "    def forward(self, y_pred, y_true):\n",
      "        # Compute the loss\n",
      "        loss = F.cross_entropy(y_pred, y_true, reduction='mean')\n",
      "\n",
      "        return loss\n",
      "\n",
      "Test function code:\n",
      " from temp_code import AutoLoss\n",
      "\n",
      "import unittest\n",
      "import torch\n",
      "\n",
      "class TestAutoLoss(unittest.TestCase):\n",
      "    def test_auto_loss(self):\n",
      "        # Testing the loss function\n",
      "        y_pred = torch.randn(1, 10)\n",
      "        y_true = torch.randn(1, 10)\n",
      "\n",
      "        loss = AutoLoss()\n",
      "        loss(y_pred, y_true)\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    unittest.main()\n",
      "\n",
      "[Attempt 1/3] Status: True\n",
      "Error Output:\n",
      "test_auto_loss (temp_test.TestAutoLoss) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.000s\n",
      "\n",
      "OK\n",
      "\n",
      "\n",
      "Tests passed successfully!\n",
      "\n",
      "Loss function generated successfully. Executing generated function.\n",
      "Loss function executed and is now ready to use!\n"
     ]
    }
   ],
   "source": [
    "model_id = \"codellama/CodeLlama-7b-Instruct-hf\"\n",
    "token = \"NONE\"\n",
    "prompt = \"The task is to classify images present in MNIST dataset\"\n",
    "\n",
    "generator = Rubick(model_id, token, prompt)\n",
    "generator.process_start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c9b7d5-dc09-4901-9bae-a8e62c76854f",
   "metadata": {},
   "source": [
    "### Defining the loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8a4686-c19b-497b-9a94-b120abc50a08",
   "metadata": {},
   "source": [
    "Here we assign the generated loss function `AutoLoss` to the variable `criterion` which will then be used for the rest of the training phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a751799e-dc93-43c6-a7dc-dd4fb39fd5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = generator.AutoLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b26167-e5e9-4d37-8be1-9bb2f7c30144",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0129f140-8aa1-44a5-87bd-8ca81f50bcfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.3972\n",
      "Epoch [2/5], Loss: 0.1888\n",
      "Epoch [3/5], Loss: 0.1356\n",
      "Epoch [4/5], Loss: 0.1087\n",
      "Epoch [5/5], Loss: 0.0909\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):  # few epochs for quick test\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/5], Loss: {running_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4000c6b7-5c92-40bf-9027-f4c8286e6833",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78afeb1d-0c9f-46e8-82ab-de9d4091fe26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 96.86%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
